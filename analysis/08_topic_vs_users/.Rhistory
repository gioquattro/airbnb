print_reviewSummary(review)
library(sqldf)
names(review)
review = as.data.table( sqldf("select * from review group by id") )
review = as.data.table( sqldf("select * from review group by author_id, listing_id, comments") )
print_reviewSummary(review)
review = english_review(review)
print_reviewSummary(review)
review = review[!author_id %in% host$Id]
print_reviewSummary(review)
library(quanteda)
mfdict <- dictionary(file = "LIWC2007_English080730.dic", format = "LIWC")
doc_term_matrix <- dfm(review$comments, stem = FALSE, dictionary = mfdict)
doc_term = data.table( data.frame(doc_term_matrix) )
detach(package:quanteda)
doc_term_processed = cbind(review[, c('author_id', 'listing_id', 'year', 'comments', 'locale',
'inferredLanguage', 'nwords'), with=F],
doc_term[, c('social', 'home', 'posemo', 'negemo'), with=F] )
View(doc_term_processed)
doc_term2 = cbind(review[, c('author_id', 'listing_id', 'year', 'comments', 'locale',
'inferredLanguage', 'nwords'), with=F],
doc_term[, c('social', 'home', 'posemo', 'negemo'), with=F] )
doc_term2$social_vs_home = (doc_term2$social+3)/(doc_term2$home+3)
doc_term2$pos_vs_neg = (doc_term2$posemo+3)/(doc_term2$negemo+3)
remove(doc_term_processed)
summary(doc_term2[,c('social', 'home',
'posemo', 'negemo',
'social_vs_home', 'pos_vs_neg'), with=F])
countries = fread("Country.csv")
countries$city[1:20]
countries$city[1:20]
doc_term2$locale[1:20]
countries = fread("Country.csv")
countries$city[1:20]
remove(countries)
countries = fread("Country.csv")
countries$city[1:20]
countries = fread("Country.csv")
countries = fread("Country2.csv")
countries$city[1:20]
doc_term2$locale[1:20]
x = " Pechino, Cina "
substr(x, 2, (nchar(x)-1) )
countries = read.csv("Country2.csv", sep = ";")
countries$city[1:20]
doc_term2$locale[1:20]
countries = as.data.table( read.csv("Country2.csv", sep = ";") )
countries$city[1:20]
doc_term2$locale[1:20]
countries = fread"Country2.csv")
countries = fread"Country2.csv")
countries = fread("Country2.csv")
countries$city[1:20]
countries = fread("Country.csv")
countries$city[1:20]
doc_term2$locale[1:20]
x = " Pechino, Cina "
x
doc_term2$locale[1]
substr(doc_term2$locale[1], 2, (nchar(doc_term2$locale[1])-1) )
substr(doc_term2$locale[1], 3, (nchar(doc_term2$locale[1])-2) )
doc_term2$locale2 = substr(doc_term2$locale, 2, (nchar(doc_term2$locale)-1) )
substr(doc_term2$locale[1], 3, (nchar(doc_term2$locale[1])-2) )
doc_term2$locale2 = substr(doc_term2$locale, 2, (nchar(doc_term2$locale)-1) )
View(doc_term2)
library(stringr)
countries$city = str_replace_all(countries$city, ' ', '')
doc_term2$locale = str_replace_all(doc_term2$locale, ' ', '')
countries$city[1:20]
doc_term2$locale[1:20]
doc_term_joined = as.data.table( sqldf("select t1.*,
t2.country as country_guest,
t3.city as city_listing,
t3.country as country_listing
from doc_term_processed t1
left join countries t2 on t1.locale=t2.city
left join listing t3 on t1.listing_id=t3.id")
)
doc_term3 = as.data.table( sqldf("select t1.*,
t2.country as country_guest,
t3.city as city_listing,
t3.country as country_listing
from doc_term2 t1
left join countries t2 on t1.locale=t2.city
left join listing t3 on t1.listing_id=t3.id")
)
View(doc_term3)
View(doc_term3)
locales =
sqldf("select locale, count(*)
from doc_term2
order by locale
order by count(*) desc")
locales =
sqldf("select locale, count(*)
from doc_term2
group by locale
order by count(*) desc")
View(locales)
locales =
sqldf("select locale, count(*) n
from doc_term2
group by locale
order by count(*) desc")
View(locales)
locales = doc_term2[, .(n=length(year)), by=locale]
View(locales)
locales = doc_term2[, .(n=length(comments)), by=locale]
View(locales)
nrow( locales[n>1] )/nrow( locales )
View(locales)
setorder(locales, n)
View(locales)
setorder(locales, -n)
View(locales)
locales$n2 = cumsum(locales$n)
View(locales)
max( locales[n>1]$n2 )
max( locales[n>1]$n2 )/nrow( locales$n2 )
max( locales[n>1]$n2 )/max( locales$n2 )
nrow( locales[n>2] )/nrow( locales )
max( locales[n>2]$n2 )/max( locales$n2 )
locales = doc_term2[, .(cnt=length(comments)), by=locale]
setorder(locales, -cnt)
locales$tcnt = cumsum(locales$cnt)
nrow( locales[cnt>2] )/nrow( locales )
max( locales[cnt>2]$tcnt )/max( locales$tcnt )
write.table(locales, row.names = F, col.names = T)
write.table(locales, row.names = F, col.names = T, file = "locales.csv")
write.table(locales, row.names = F, col.names = T, file = "locales.csv", sep = ";")
nrow( locales[cnt>2] )/nrow( locales )
max( locales[cnt>2]$tcnt )/max( locales$tcnt )
countries = fread("Country.csv")
library(stringr)
countries$city = str_replace_all(countries$city, ' ', '')
doc_term2$locale = str_replace_all(doc_term2$locale, ' ', '')
doc_term3 = as.data.table( sqldf("select t1.*,
t2.country as country_guest,
t3.city as city_listing,
t3.country as country_listing
from doc_term2 t1
left join countries t2 on t1.locale=t2.city
left join listing t3 on t1.listing_id=t3.id")
)
View(doc_term3)
countries_guest = doc_term3[, .(cnt=length()), by=country_guest]
countries_guest = doc_term3[, .(cnt=length(comments)), by=country_guest]
View(countries_guest)
setorder(countries_guest, -cnt)
View(countries_guest)
countries_listing = doc_term3[, .(cnt=length(comments)), by=country_listing]
setorder(countries_listing, -cnt)
View(countries_listing)
source("myFunctions.R")
#
# loading datast
#
library(RMySQL)
mydb = dbConnect(MySQL(), user='root', password='', dbname='airbnb', host='127.0.0.1')
# mydb = dbConnect(MySQL(), user='root', password='1234567890', dbname='airbnb', host='127.0.0.1')
dbListTables(mydb)
guest = load_from_db(mydb, "guest")
host = load_from_db(mydb, "host")
listing = load_from_db(mydb, "listing")
review = load_from_db(mydb, "review")
review_language = load_from_db(mydb, "review_language")
word_count = load_from_db(mydb, "word_count")
detach(package:RMySQL)
#
# join review and language
#
setkey(review, idReview)
setkey(review_language, idReview)
review = review[review_language, nomatch=0]
remove(review_language)
#
# pre-processing
#
review = pre_proces_review(review)
print_reviewSummary(review)
#
# removing invalid entries and duplicates
#
review = review[author_id!='#']
print_reviewSummary(review)
library(sqldf)
review = as.data.table( sqldf("select * from review group by id") )
review = as.data.table( sqldf("select * from review group by author_id, listing_id, comments") )
print_reviewSummary(review)
#
# reviews only for guests which have a year
#
# review = review[!(author_id %in% listing$id_host) & !is.na(year)]
# print_reviewSummary(review)
#
# reviews only in English
#
review = english_review(review)
print_reviewSummary(review)
#
# length of reviews (too short reviews may not give statistical significant results)
#
# ggplot(review, aes(x=factor(year), y=nwords)) +
#   geom_violin(alpha=0.5, fill=3) +
#   geom_boxplot(width=.1, fill=7, outlier.size=NA) +
#   scale_y_log10(breaks=c(1,5,10,50,100,500,1000,5000))
#
# ggplot(review, aes(x=factor(year), y=nwords)) +
#   geom_jitter(alpha=0.01, size=.1, width=.3) +
#   geom_violin(alpha=0.5, fill=3) +
#   geom_boxplot(width=.1, fill=7, outlier.size=NA) +
#   ylim(0,200)
#
# review = review[nwords>10]
# print_reviewSummary(review)
#
# not an host
#
review = review[!author_id %in% host$Id]
print_reviewSummary(review)
#
# extract doc_term
#
library(quanteda)
mfdict <- dictionary(file = "LIWC2007_English080730.dic", format = "LIWC")
doc_term_matrix <- dfm(review$comments, stem = FALSE, dictionary = mfdict)
# doc_term_matrixN = doc_term_matrix/review$nwords
doc_term = data.table( data.frame(doc_term_matrix) )
detach(package:quanteda)
#
# defining metrics
#
doc_term2 = cbind(review[, c('author_id', 'listing_id', 'year', 'comments', 'locale',
'inferredLanguage', 'nwords'), with=F],
doc_term[, c('social', 'home', 'posemo', 'negemo'), with=F] )
doc_term2$social_vs_home = (doc_term2$social+3)/(doc_term2$home+3)
doc_term2$pos_vs_neg = (doc_term2$posemo+3)/(doc_term2$negemo+3)
summary(doc_term2[,c('social', 'home',
'posemo', 'negemo',
'social_vs_home', 'pos_vs_neg'), with=F])
#   social            home            posemo           negemo        social_vs_home     pos_vs_neg
# Min.   : 0.000   Min.   : 0.000   Min.   : 0.000   Min.   : 0.0000   Min.   :0.2727   Min.   :0.4444
# 1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 3.000   1st Qu.: 0.0000   1st Qu.:1.1667   1st Qu.:2.0000
# Median : 5.000   Median : 2.000   Median : 5.000   Median : 0.0000   Median :1.6250   Median :2.3333
# Mean   : 6.505   Mean   : 2.345   Mean   : 5.685   Mean   : 0.2537   Mean   :1.8521   Mean   :2.7145
# 3rd Qu.: 9.000   3rd Qu.: 3.000   3rd Qu.: 7.000   3rd Qu.: 0.0000   3rd Qu.:2.3333   3rd Qu.:3.3333
# Max.   :56.000   Max.   :20.000   Max.   :36.000   Max.   :15.0000   Max.   :8.4286   Max.   :9.7500
countries = fread("Country.csv")
library(stringr)
countries$city = str_replace_all(countries$city, ' ', '')
doc_term2$locale = str_replace_all(doc_term2$locale, ' ', '')
doc_term3 = as.data.table( sqldf("select t1.*,
t2.country as country_guest,
t3.city as city_listing,
t3.country as country_listing
from doc_term2 t1
left join countries t2 on t1.locale=t2.city
left join listing t3 on t1.listing_id=t3.id")
)
doc_term3$country_guest = str_replace_all(doc_term3$country_guest, '"', '')
doc_term3$country_listing = str_replace_all(doc_term3$country_listing, '"', '')
cultural = fread("world_cultural_factors.csv")
countries_guest = doc_term3[, .(cnt=length(comments)), by=country_guest]
setorder(countries_guest, -cnt)
countries_listing = doc_term3[, .(cnt=length(comments)), by=country_listing]
setorder(countries_listing, -cnt)
countries_guest
View(countries)
View(countries_guest)
View(countries_listing)
View(cultural)
cultural_match =
sqldf("select t1.country, t2.country_guest
from cultural t1
left join countries_guest t2 on t1.country=t2.country_guest")
View(cultural_match)
cultural_match =
sqldf("select t1.country, t2.country_guest
from cultural t1
left join countries_guest t2 on t1.country=t2.country_guest
left join countries_listing t3 on t1.country=t3.country_listing")
View(cultural_match)
cultural_match =
sqldf("select t1.country, t2.country_guest, t3.country_listing
from cultural t1
left join countries_guest t2 on t1.country=t2.country_guest
left join countries_listing t3 on t1.country=t3.country_listing")
View(cultural_match)
remove(cultural_match)
View(countries_guest)
cultural$country
countries_guest$country_guest[1:50]
countries_listing$country_listing[1:20]
countries_guest$country_guest[1:20]
doc_term3[country_guest=="USA"] <- "United States"
warnings()
s
countries_guest = doc_term3[, .(cnt=length(comments)), by=country_guest]
setorder(countries_guest, -cnt)
countries_guest$country_guest[1:20]
doc_term3[country_guest=="UK"] <- "United Kingdom"
doc_term4 = as.data.table(
sqldf("select t1.*, t2.GDP_per_capita_in_dollars GDP_guest, t3.GDP_per_capita_in_dollars GDP_listing
from doc_term3 t1
left join cultural t2 on t1.country_guest=t2.country
left join cultural t3 on t1.country_listing=t3.country")
)
View(doc_term4)
doc_term4$GDP_delta = doc_term4$GDP_listing - doc_term4$GDP_guest
View(doc_term4)
names(doc_term4)
ggplot( doc_term4, aes(x=GDP_guest, y=social_vs_home) ) +
geom_point() +
geom_smooth()
ggplot( doc_term4, aes(x=GDP_guest, y=social_vs_home) ) +
geom_point(size=.1, alpha=.1) +
geom_smooth()
ggplot( doc_term4, aes(x=GDP_guest, y=social_vs_home) ) +
geom_point(size=.5, alpha=.01) +
geom_smooth()
ggplot( doc_term4, aes(x=GDP_guest, y=pos_vs_neg) ) +
geom_point(size=.5, alpha=.01) +
geom_smooth()
doc_term4$GDP_guest_br = cut(doc_term4$GDP_guest, breaks=10)
View(doc_term4)
doc_term4$GDP_guest_br = cut(doc_term4$GDP_guest, breaks=10)
doc_term4$GDP_listing_br = cut(doc_term4$GDP_listing, breaks=10)
doc_term4$GDP_delta_br = cut(doc_term4$GDP_delta, breaks=10)
ggplot( doc_term4, aes(x=GDP_guest_br, y=social_vs_home) ) +
geom_point(size=.5, alpha=.01) +
geom_boxplot()
ggplot( doc_term4, aes(x=GDP_guest_br, y=social_vs_home) ) +
geom_point(size=.5, alpha=.01) +
geom_boxplot(outlier.shape=NA)
ggplot( doc_term4, aes(x=GDP_guest_br, y=social_vs_home) ) +
geom_boxplot(outlier.shape=NA) +
geom_point(size=.5, alpha=.01)
names(doc_term4)
ggplot( doc_term4, aes(x=GDP_listing_br, y=social_vs_home) ) +
geom_boxplot(outlier.shape=NA) +
geom_point(size=.5, alpha=.01)
ggplot( doc_term4, aes(x=GDP_guest_br, y=social_vs_home) ) +
geom_boxplot(outlier.shape=NA) +
geom_point(size=.5, alpha=.01)
ggplot( doc_term4, aes(x=GDP_guest_br, y=pos_vs_neg) ) +
geom_boxplot(outlier.shape=NA) +
geom_point(size=.5, alpha=.01)
ggplot( doc_term4, aes(x=GDP_listing_br, y=social_vs_home) ) +
geom_boxplot(outlier.shape=NA) +
geom_point(size=.5, alpha=.01)
ggplot( doc_term4, aes(x=GDP_listing_br, y=pos_vs_neg) ) +
geom_boxplot(outlier.shape=NA) +
geom_point(size=.5, alpha=.01)
ggplot( doc_term4, aes(x=GDP_delta_br, y=social_vs_home) ) +
geom_boxplot(outlier.shape=NA) +
geom_point(size=.5, alpha=.01)
ggplot( doc_term4, aes(x=GDP_delta_br, y=pos_vs_neg) ) +
geom_boxplot(outlier.shape=NA) +
geom_point(size=.5, alpha=.01)
doc_termLS = doc_term4[social_vs_home<1.1]
doc_termHS = doc_term4[social_vs_home>2.33]
doc_termLP = doc_term4[pos_vs_neg<2]
doc_termHP = doc_term4[pos_vs_neg>3.33]
summary( doc_termLS[, c('GDP_guest', 'GDP_listing', 'GDP_delta'), with=F)
guest_LS = guest[id %in% review_g_LS$author_id]
guest_HS = guest[id %in% review_g_HS$author_id]
guest_LP = guest[id %in% review_g_LP$author_id]
guest_HP = guest[id %in% review_g_HP$author_id]
guest_HS$location[1:50]
listing$city[1:50]
#
# sanity check
#
table(doc_term_processed$inferredLanguage)
# english
# 43259
testSHH = doc_term_processed[social_vs_home>10]
testSHL = doc_term_processed[social_vs_home<.5]
testPNH = doc_term_processed[pos_vs_neg>7]
testPNL = doc_term_processed[pos_vs_neg<.5]
testSHH$comments[1:20]
testSHL$comments[1:20]
testPNH$comments[1:20]
testPNL$comments[1:20]
#
# shorter reviews for homes and negative emotions?
#
printSocialHomeWords = function(doc_term_processed, alpha, selected_year=NA)
{
if (is.na(selected_year)) {
selected_year="All years"
} else {
doc_term_processed = doc_term_processed[year==selected_year]
}
mycor = cor.test(doc_term_processed$social_vs_home, doc_term_processed$nwords)
nstars = ifelse(mycor$p.value<0.001, "***",
ifelse(mycor$p.value<0.01, "**",
ifelse(mycor$p.value<0.05, "*",
ifelse(mycor$p.value<0.1, ".", ""))))
stat = paste(round(mycor$estimate,2), nstars)
print(
ggplot(doc_term_processed, aes(x=social_vs_home, y=nwords)) +
geom_point(alpha=alpha) +
geom_smooth(method = "lm") +
geom_smooth(col=2) +
scale_x_log10() +
scale_y_log10() +
annotate("text", label=paste("cor =", stat), x = 1, y = 1000, size = 4, colour = "red") +
ggtitle(selected_year)
)
}
printSocialHomeWords(doc_term_processed, alpha=0.01)
printSocialHomeWords(doc_term_processed, alpha=0.2, selected_year=2010)
printSocialHomeWords(doc_term_processed, alpha=0.2, selected_year=2011)
printSocialHomeWords(doc_term_processed, alpha=0.1, selected_year=2012)
printSocialHomeWords(doc_term_processed, alpha=0.1, selected_year=2013)
printSocialHomeWords(doc_term_processed, alpha=0.05, selected_year=2014)
printSocialHomeWords(doc_term_processed, alpha=0.05, selected_year=2015)
printSocialHomeWords(doc_term_processed, alpha=0.02, selected_year=2016)
printSocialHomeWords(doc_term_processed, alpha=0.01, selected_year=2017)
printPosNegWords = function(doc_term_processed, alpha, selected_year=NA)
{
if (is.na(selected_year)) {
selected_year="All years"
} else {
doc_term_processed = doc_term_processed[year==selected_year]
}
mycor = cor.test(doc_term_processed$pos_vs_neg, doc_term_processed$nwords)
nstars = ifelse(mycor$p.value<0.001, "***",
ifelse(mycor$p.value<0.01, "**",
ifelse(mycor$p.value<0.05, "*",
ifelse(mycor$p.value<0.1, ".", ""))))
stat = paste(round(mycor$estimate,2), nstars)
print(
ggplot(doc_term_processed, aes(x=pos_vs_neg, y=nwords)) +
geom_point(alpha=alpha) +
geom_smooth(method = "lm") +
geom_smooth(col=2) +
scale_x_log10() +
scale_y_log10() +
annotate("text", label=paste("cor =", stat), x = 1, y = 1000, size = 4, colour = "red") +
ggtitle(selected_year)
)
}
printPosNegWords(doc_term_processed, alpha=0.01)
printPosNegWords(doc_term_processed, alpha=0.2, selected_year=2010)
printPosNegWords(doc_term_processed, alpha=0.2, selected_year=2011)
printPosNegWords(doc_term_processed, alpha=0.1, selected_year=2012)
printPosNegWords(doc_term_processed, alpha=0.1, selected_year=2013)
printPosNegWords(doc_term_processed, alpha=0.05, selected_year=2014)
printPosNegWords(doc_term_processed, alpha=0.05, selected_year=2015)
printPosNegWords(doc_term_processed, alpha=0.02, selected_year=2016)
printPosNegWords(doc_term_processed, alpha=0.01, selected_year=2017)
#
# distributions
#
ggplot(doc_term_processed, aes(social_vs_home)) + geom_histogram(col=1, fill=3, bins=100) + scale_x_log10()
ggplot(doc_term_processed, aes(pos_vs_neg)) + geom_histogram(col=1, fill=3, bins=100) + scale_x_log10() + scale_y_sqrt()
#
# visualise social vs emotion
#
printSocialHomePosNeg = function(doc_term_processed, alpha, selected_year=NA)
{
if (is.na(selected_year)) {
selected_year="All years"
} else {
doc_term_processed = doc_term_processed[year==selected_year]
}
mycor = cor.test(doc_term_processed$social_vs_home, doc_term_processed$pos_vs_neg)
nstars = ifelse(mycor$p.value<0.001, "***",
ifelse(mycor$p.value<0.01, "**",
ifelse(mycor$p.value<0.05, "*",
ifelse(mycor$p.value<0.1, ".", ""))))
stat = paste(round(mycor$estimate,2), nstars)
print(
ggplot(doc_term_processed, aes(x=pos_vs_neg, y=social_vs_home)) +
geom_point(alpha=alpha) +
geom_smooth(method = "lm") +
geom_smooth(col=2) +
scale_x_log10() +
scale_y_log10() +
annotate("text", label=paste("cor =", stat), x = 1, y = 1000, size = 4, colour = "red") +
ggtitle(selected_year)
)
}
printSocialHomePosNeg(doc_term_processed, alpha=0.01)
printSocialHomePosNeg(doc_term_processed, alpha=0.2, selected_year=2010)
printSocialHomePosNeg(doc_term_processed, alpha=0.2, selected_year=2011)
printSocialHomePosNeg(doc_term_processed, alpha=0.1, selected_year=2012)
printSocialHomePosNeg(doc_term_processed, alpha=0.1, selected_year=2013)
printSocialHomePosNeg(doc_term_processed, alpha=0.05, selected_year=2014)
printSocialHomePosNeg(doc_term_processed, alpha=0.05, selected_year=2015)
printSocialHomePosNeg(doc_term_processed, alpha=0.02, selected_year=2016)
printSocialHomePosNeg(doc_term_processed, alpha=0.01, selected_year=2017)
#
# visualise evolution over time
#
ggplot(doc_term_processed, aes(x=factor(year), y=social_vs_home)) +
geom_jitter(alpha=0.01, size=.05, width=.3) +
geom_violin(alpha=0.7, fill=3) +
geom_boxplot(width=.1, fill=7, outlier.size=NA) +
scale_y_log10()
ggplot(doc_term_processed, aes(x=factor(year), y=pos_vs_neg)) +
geom_jitter(alpha=0.01, size=.05, width=.3) +
geom_violin(alpha=0.7, fill=3) +
geom_boxplot(width=.1, fill=7, outlier.size=NA) +
scale_y_log10()
summary( doc_termLS[, c('GDP_guest', 'GDP_listing', 'GDP_delta'), with=F] )
summary( doc_termLS[, c('GDP_guest', 'GDP_listing', 'GDP_delta'), with=F] )
summary( doc_termHS[, c('GDP_guest', 'GDP_listing', 'GDP_delta'), with=F] )
summary( doc_termLP[, c('GDP_guest', 'GDP_listing', 'GDP_delta'), with=F] )
summary( doc_termHP[, c('GDP_guest', 'GDP_listing', 'GDP_delta'), with=F] )
