#
processing_tuning = list(
feature_tail = c(T, F),
feature_window = c(1, 10),
roll_function = c('max', 'mean')
)
# WARNING: do not insert here prob_thr. This parameter is tuned anyway if k-fold is selected.
model_tuning = list(
num_trees = c(30, 500)
)
#
# loading datasets
#
flights = fread( paste0("data/", param$aircraft_type, "/input_flights.csv") )
flight_feature = fread( paste0("data/", param$aircraft_type, "/input_predictors.csv") )
flight_severe = fread( paste0("data/", param$aircraft_type, "/input_targets.csv") )
related_chapters = fread( paste0("data/", param$aircraft_type, "/input_related_chapters.csv"), header=TRUE )
related_chapters = related_chapters[2:.N]
#
# flight_id is generally a string
#
flights$flight_id = as.character(flights$flight_id)
flight_feature$flight_id = as.character(flight_feature$flight_id)
flight_severe$flight_id = as.character(flight_severe$flight_id)
#
# checking dataset format and consistency
#
data_check(flights, table_structure=c('tail', 'flight_id', 'departure_time'))
data_check(flight_feature, table_structure=c('flight_id', 'fault_code'))
data_check(flight_severe, table_structure=c('flight_id', 'fault_code'))
if ( param$delta_safe < param$repetition_threshold )
stop("delta_safe must be greater than repetition_threshold")
if ( param$delta_safe <= param$prediction_lag )
stop("delta_safe must be greater than prediction_lag")
if ( param$delta_safe <= param$within_lag[1] | param$delta_safe <= param$within_lag[2] )
stop("delta_safe must be greater than within_lag")
#
# creating header (all the flight_ids per train and test) and processing it
#
header = create_header(flights)
header$tmstamp = convert_date_time_to_tmst(header$departure_time)
header = add_flightseq_to_header(header)
#
# creating target/outcome variable (by shifting target fault) and processing it
#
header = add_severe_to_header(header, flight_severe, param$target_fault)
header = add_outcome_to_header(header, param$prediction_lag)
add_row_filters_to_header(header, param$repetition_threshold, param$delta_safe)
header = add_real_and_fake_targets(header, param$repetition_threshold,
param$delta_safe, param$head_cols)
#
# creating feature vectors (<flight_id, feature_1, ... , feature_n>) and joining it with the header
#
features = get_features(flight_feature, header, param$delta_safe)
feature_table = create_feature_table(flight_feature, features)
dt = join_header_features(header, feature_table)
names(dt) = make.names(names(dt)) # converting variable names to all be legal
#
# getting summary statistic of the input data
#
data_summary = get_summary_data(dt)
#
# if there are not enough positive cases, it doesn't build the model
#
# n_pos <- dt[repetitive==FALSE, sum(target, na.rm=TRUE)]
writeLines(paste0("...data has ", data_summary$positive_cases_noRep, " non-repetitive positive cases."))
if (data_summary$positive_cases_noRep <= param$k_folds)
stop("Not enough positive cases. No model built. At least one positive case per fold is needed.")
#
# splitting into train and test sets
#
writeLines("splitting data into train and test sets...")
split_points <- get_temporal_split(dt, split_size=param$train_size, verbose=T)
train = split_data(dt, split_points, align='left')
test = split_data(dt, split_points, align='right')
writeLines(sprintf("...train has %d rows and %d non-repetitive positive cases (%.2f%%)",
train[, .N], train[, sum(real_target)], train[, sum(real_target)/.N*100]))
writeLines(sprintf("...test has %d rows and %d non-repetitive positive cases (%.2f%%)",
test[, .N], test[, sum(real_target)], test[, sum(real_target)/.N*100]))
#
# to free memory
#
rm(dt)
rm(feature_table)
writeLines("k-fold validation selected. Searching for the best model_parameters.")
# gnerating the configurations containing all the parameters,
# the ones we want to tune and the ones we do not
for ( i in 1:(length(processing_tuning)) )
{
model_par_field = names(processing_tuning)[i]
processing_config[model_par_field] = processing_tuning[model_par_field]
}
for ( i in 1:(length(model_tuning)) )
{
model_par_field = names(model_tuning)[i]
model_config[model_par_field] = model_tuning[model_par_field]
}
param_grids = NULL
for ( i in 1:(length(processing_tuning)) )
{
model_par_field = names(processing_tuning)[i]
writeLines( paste("Opmising", model_par_field, "field...") )
res_k_fold = evaluate_config(train, param$k_folds, param$max_fold_tests,
param$head_cols, related_chapters,
processing_config, model_config, model_par_field)
processing_config[model_par_field] = res_k_fold$best_config
param_grids = rbind(param_grids, res_k_fold$param_grid)
}
ceiling(3.1)
round(0.1)
2/3
round(0.1)
ceiling(3.1)
length(model_tuning)
for ( i in 1:(length(model_tuning)) )
{
model_par_field = names(model_tuning)[i]
writeLines( paste("Opmising", model_par_field, "field...") )
res_k_fold = evaluate_config(train, param$k_folds, param$max_fold_tests,
param$head_cols, related_chapters,
processing_config, model_config, model_par_field)
model_config[model_par_field] = res_k_fold$best_config
param_grids = rbind(param_grids, res_k_fold$param_grid)
}
remove(model_par_field)
remove(res_k_fold)
prob_ths = NULL
kfold_models <- vector("list", param$k_folds)
writeLines("Tuning probability threshold...")
fold=1
train_test_fold = get_train_test_from_kfold(train, fold, param$k_folds)
train_kfold = train_test_fold$train
test_kfold = train_test_fold$test
train_test_fold = get_train_test_from_kfold(train, fold, param$k_folds)
kfold_train = train_test_fold$train
kfold_test = train_test_fold$test
kfold_train = transform(kfold_train, param$head_cols, model_configuration, related_chapters)
processing_config
kfold_train = transform(kfold_train, param$head_cols, processing_config, related_chapters)
kfold_train
kfold_train = transform(kfold_train, param$head_cols, related_chapters, processing_config)
kfold_test = transform(kfold_test, param$head_cols, related_chapters, processing_config)
kfold_model = get_model_object(kfold_train, kfold_test, param$head_cols, model_configuration)
model_config
kfold_model = get_model_object(kfold_train, kfold_test, param$head_cols, model_config)
prob_th = tune_prob_thr(kfold_model$preds_test)
prob_th
prob_ths = c(prob_ths, prob_th)
kfold_models[[fold]] = kfold_model
prob_ths = NULL
kfold_models <- vector("list", param$k_folds)
writeLines("Tuning probability threshold...")
for (fold in 1:param$k_folds)
{
train_test_fold = get_train_test_from_kfold(train, fold, param$k_folds)
kfold_train = train_test_fold$train
kfold_test = train_test_fold$test
kfold_train = transform(kfold_train, param$head_cols, related_chapters, processing_config)
kfold_test = transform(kfold_test, param$head_cols, related_chapters, processing_config)
kfold_model = get_model_object(kfold_train, kfold_test, param$head_cols, model_config)
prob_th = tune_prob_thr(kfold_model$preds_test)
# updating results
prob_ths = c(prob_ths, prob_th)
kfold_models[[fold]] = kfold_model
}
model_configuration$prob_thr = mean(prob_ths)
model_config$prob_thr = mean(prob_ths)
remove(kfold_model)
remove(prob_th)
#
# double check that the k-fold has found a valid rolling configuration
#
if ( param$delta_safe <= (processing_config$feature_window + processing_config$target_window) )
stop("delta_safe must be greater than feature_window+target_window")
#
# applying the chosen configuration (default model parameters or the one found by k-fold) to build our prediction model
#
train = transform(train, param$head_cols, related_chapters, processing_config, verbose=T)
test = transform(test, param$head_cols, related_chapters, processing_config, verbose=T)
final_model = get_model_object(train, test, param$head_cols, model_config, verbose=T)
accuracy_train = final_model$accuracy_train
accuracy_test = final_model$accuracy_test
#
# Having a summary of everything
#
performance = data.frame(
#
# about initial thresholds
param_target = param$target_fault,
param_aircraft = param$aircraft_type,
param_trainSize = param$train_size,
param_kFolds = param$k_folds,
param_predLag = param$prediction_lag,
param_withinMin = param$within_lag[1],
param_withinMax = param$within_lag[2],
param_repTh = param$repetition_threshold,
param_deltaSafe = param$delta_safe,
#
# about post processing
processing_ex = processing_config$extented_chapters,
processing_ft = processing_config$feature_tail,
processing_fw = processing_config$feature_window,
processing_roll = processing_config$roll_function,
processing_tw = processing_config$target_window,
#
# about model parameters
modelConfig_ntree = model_config$num_trees,
modelConfig_caseWgt = model_config$case_weight,
modelConfig_nodeSize = model_config$min_node_size,
modelConfig_probTh = model_config$prob_thr,
#
# about data
dataStat_posNoRep = data_summary$positive_cases_noRep,
dataStat_repetitiveRatio = data_summary$repetitive_ratio,
dataStat_imbalance = data_summary$positive_imbalance,
dataStat_diveristyTail = data_summary$diversity_tail,
dataStat_diveristyTime = data_summary$diversity_time,
dataStat_medianTimeRatio = data_summary$median_time_ratio,
#
# about train-test split
trainTest_imbalanceTrain=train[repetitive==FALSE, sum(target)/.N],
trainTest_imbalanceTest=test[repetitive==FALSE, sum(target)/.N],
#
# accuracies train
train_ROCauc=accuracy_train$roc_auc,
train_PRauc=accuracy_train$pr_auc,
train_TP=accuracy_train$TP,
train_FP=accuracy_train$FP,
train_TN=accuracy_train$TN,
train_FN=accuracy_train$FN,
train_precision=accuracy_train$precision,
train_recall=accuracy_train$recall,
train_f1=accuracy_train$f1,
train_f2=accuracy_train$f2,
train_f3=accuracy_train$f3,
train_f4=accuracy_train$f4,
#
# accuracies tuning
tuning_meanPRauc=ifelse(param$k_folds>1, mean(param_grids$accuracy), NA),
tuning_medianPRauc=ifelse(param$k_folds>1, median(param_grids$accuracy), NA),
#
# accuracies test
test_ROCauc=accuracy_test$roc_auc,
test_PRauc=accuracy_test$pr_auc,
test_TP=accuracy_test$TP,
test_FP=accuracy_test$FP,
test_TN=accuracy_test$TN,
test_FN=accuracy_test$FN,
test_precision=accuracy_test$precision,
test_recall=accuracy_test$recall,
test_f1=accuracy_test$f1,
test_f2=accuracy_test$f2,
test_f3=accuracy_test$f3,
test_f4=accuracy_test$f4
)
#
# Saving on files outcome, summary and plots
#
if ( !file.exists(param$results_dir) )
dir.create(param$results_dir, recursive=TRUE)
sfx_name = paste0("target", param$target_fault,
"_lag", param$prediction_lag,
"_kfold", param$k_folds)
plotTimeseries(final_model$preds_train,
final_model$preds_test,
param$target_fault,
pdfFileName=paste0(param$results_dir, sfx_name, "_plotTime.pdf")
)
if (param$k_folds>1)
{
plotAccuracyTuningVsTest(param_grids,
final_model$defaut_accuracy,
pdfFileName=paste0(param$results_dir, sfx_name, "_plotTuningVsTest.pdf"))
for (fold in 1:param$k_folds)
{
kfold_model = kfold_models[[fold]]
plotTimeseries(kfold_model$preds_train,
kfold_model$preds_test,
param$target_fault,
pdfFileName=paste0(param$results_dir, sfx_name, "_fold", fold, "_plotTime.pdf")
)
}
}
write.table(final_model$preds_train,
sep = ",", eol = "\n", na = "NA", dec = ".", row.names = F, col.names = T,
gzfile(paste0(param$results_dir, sfx_name, "_predsTrain.csv.gz")))
write.table(final_model$preds_test,
sep = ",", eol = "\n", na = "NA", dec = ".", row.names = F, col.names = T,
gzfile(paste0(param$results_dir, sfx_name, "_predsTest.csv.gz")))
write.table(split_points,
sep = ",", eol = "\n", na = "NA", dec = ".", row.names = F, col.names = T,
file=paste0(param$results_dir, sfx_name, "_splitPoints.csv"))
write.table(t(performance),
file=paste0(param$results_dir, sfx_name, "_performance.csv"),
sep = ",", eol = "\n", na = "NA", dec = ".", row.names = T, col.names = F)
if (param$k_folds>1){
save(final_model, param, processing_config, model_config, kfold_models, param_grids,
file=paste0(param$results_dir, sfx_name, "_rdata.RData"))
} else {
save(final_model, param, processing_config, model_config,
file=paste0(param$results_dir, sfx_name, "_rdata.RData"))
}
print(Sys.time() - t0)
beep()
model = build_model(train, param$head_cols,
num_trees=model_config$num_trees,
min_node_size=model_config$min_node_size,
case_weights=model_config$case_weight)
model
importance( model$clf )
varImp( model$clf )
model$clf
build_model <- function(train, head_cols, num_trees=500, min_node_size=NA, case_weights=NA)
{
feature_names = setdiff(names(train), head_cols)
if ( is.na(min_node_size) ) min_node_size=NULL
if ( is.na(case_weights) ) case_weights=NULL
train_sample = sample_observations(train, use_fake_target=T)
x_train = train_sample[, feature_names, with=FALSE]
y_train = as.factor( train_sample[, fake_target] )
# class_weight = 1.0 / table(y_train)
# rf_model <- randomForest(y_train ~ .,  data=x_train, classwt=class_weight)
clf = ranger(y_train ~ ., data=x_train,
probability=TRUE,
num.trees=num_trees,
importance='impurity',
min.node.size=min_node_size,
case.weights=case_weights)
list(clf = clf,
num_trees=num_trees,
min_node_size=min_node_size,
case_weights=case_weights,
feature_names = feature_names,
features = length(feature_names)
)
}
model = build_model(train, param$head_cols,
num_trees=model_config$num_trees,
min_node_size=model_config$min_node_size,
case_weights=model_config$case_weight)
importance( model$clf )
varImp( model$clf )
importance
importance( model$clf )
var_imp = importance( model$clf )
var_imp = data.frame( importance(model$clf) )
var_imp
var_imp$predictor = row.names(var_imp)
var_imp
names(var_imp) = c("importance", "predictor")
var_imp
var_imp = sqldf("select predictor, importance from var_imp order by importance desc")
var_imp
var_imp = importance_ratio = var_imp$importance/max(var_imp$importance)
var_imp
if (verbose == T)
writeLines("Getting feature importance...")
var_imp = data.frame( importance(model$clf) )
var_imp$predictor = row.names(var_imp)
names(var_imp) = c("importance", "predictor")
var_imp = sqldf("select predictor, importance from var_imp order by importance desc")
if ( nrow(var_imp)>0 )
var_imp$importance_ratio = var_imp$importance/max(var_imp$importance)
var_imp
var_imp = sqldf("select * from var_imp where importance_ratio>0.05")
var_imp = sqldf("select * from var_imp where importance_ratio>0.1")
var_imp = sqldf("select * from var_imp where importance_ratio>0.2")
if (verbose == T)
writeLines("Getting feature importance...")
var_imp = data.frame( importance(model$clf) )
var_imp$predictor = row.names(var_imp)
names(var_imp) = c("importance", "predictor")
var_imp = sqldf("select predictor, importance from var_imp order by importance desc")
if ( nrow(var_imp)>0 )
{
var_imp$importance_ratio = var_imp$importance/max(var_imp$importance)
var_imp = sqldf("select * from var_imp where importance_ratio>0.1")
}
var_imp
source('~/Documents/github_docs/AirlineDataCentre_github/hal9000/hal9000.R', echo=TRUE)
setwd("~/Dropbox/work/papers/papers2017/TBD (airbnb)/data")
x = read.csv("insideairbnb.csv")
x = read.csv("insideairbnb.csv")
x = read.csv("insideairbnb.csv")
x = read.csv("insideairbnb2.csv")
x = read.csv("insideairbnb2.csv")
View(x)
remove()
remove(x)
df = read.csv("insideairbnb2.csv")
df$num_listings = df$apartments + df$private_rooms + df$shared_rooms
df$ratio_apartments = df$apartments / df$num_listings
df$ratio_private_rooms = df$private_rooms / df$num_listings
df$ratio_shared_rooms = df$shared_rooms / df$num_listings
library(ggplot2)
names(df)
ggplot(df, eas(x=num_listings, y=ratio_apartments)) + geom_point()
ggplot(df, aes(x=num_listings, y=ratio_apartments)) + geom_point()
ggplot(df, aes(x=num_listings, y=ratio_apartments)) + geom_point() + geom_text()
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) + geom_point() + geom_text()
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) + geom_point() + geom_label()
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) + geom_point() + geom_label(col=country)
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) + geom_point() + geom_label(aes(col=country))
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) + geom_point() + geom_label(aes(fill=country))
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) +
geom_point() +
geom_label(aes(fill=country)) +
theme(legend.position="none")
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) +
geom_point() +
geom_label(size=1, aes(fill=country)) +
theme(legend.position="none")
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) +
geom_point() +
geom_label(size=2, aes(fill=country)) +
theme(legend.position="none")
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) +
geom_point() +
geom_label(size=2, alpha=0.2, aes(fill=country)) +
theme(legend.position="none")
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) +
geom_label(size=2, alpha=0.2, aes(fill=country)) +
theme(legend.position="none")
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) +
geom_label(size=2, alpha=0.2, aes(fill=country)) +
scale_x_log10(breaks=c(1,10,100,1000,10000,20000,50000)) +
theme(legend.position="none")
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) +
geom_label(size=2, alpha=0.2, aes(fill=country)) +
scale_x_log10(breaks=c(1000,2000,5000,10000,20000,50000)) +
theme(legend.position="none")
ggplot(df, aes(x=num_listings, y=ratio_apartments, label=city)) +
geom_label(size=2, alpha=0.5, aes(fill=country)) +
scale_x_log10(breaks=c(1000,2000,5000,10000,20000,50000)) +
theme(legend.position="none")
View(df)
unique(df$country)
table(df$country)
ggplot(df, aes(x=num_listings, y=ratio_private_rooms, label=city)) +
geom_label(size=2, alpha=0.5, aes(fill=country)) +
scale_x_log10(breaks=c(1000,2000,5000,10000,20000,50000)) +
theme(legend.position="none")
ggplot(df, aes(x=num_listings, y=ratio_shared_rooms, label=city)) +
geom_label(size=2, alpha=0.5, aes(fill=country)) +
scale_x_log10(breaks=c(1000,2000,5000,10000,20000,50000)) +
theme(legend.position="none")
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat = identity)
ggplot(df, aes(x=city, y=num_listings)) + geom_point()
ggplot(df, aes(x=city, y=num_listings)) + geom_bar()
ggplot(df, aes(x=city, y=num_listings)) + geom_point(type='h')
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity')
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none")
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, hjust = -1))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, hjust = 0))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 1))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = -1))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = -0.5))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = -0.1))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = -0.01))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = -0.001))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 0))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 1))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 0.5))
ggplot(df, aes(x=city, y=num_listings)) + geom_bar(stat='identity', aes(fill=paste0(country,country))) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 0.5))
ggplot(df, aes(x=paste0(city,country), y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 0.5))
ggplot(df, aes(x=paste0(city," - ",country), y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 0.5))
ggplot(df, aes(x=paste0(city,", ",country), y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 0.5))
library(ggplot2)
df = read.csv("insideairbnb.csv")
df$num_listings = df$apartments + df$private_rooms + df$shared_rooms
df$bnb_penetration = df$num_listings / df$poulation
df$ratio_apartments = df$apartments / df$num_listings
df$ratio_private_rooms = df$private_rooms / df$num_listings
df$ratio_shared_rooms = df$shared_rooms / df$num_listings
names(df)
table(df$country)
ggplot(df, aes(x=paste0(city,", ",country), y=bnb_penetration)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 0.5))
ggplot(df, aes(x=paste0(city,", ",country), y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 0.5))
ggplot(df, aes(num_listings)) + geom_histogram(aes(fill=country))
ggplot(df, aes(num_listings)) + geom_histogram()
ggplot(df, aes(num_listings)) + geom_histogram(col=1, fill=3)
ggplot(df, aes(num_listings)) + geom_histogram(col=1, aes(fill=country))
ggplot(df, aes(x=paste0(city,", ",country), y=num_listings)) + geom_bar(stat='identity', aes(fill=country)) +
theme(legend.position="none", axis.text.x = element_text(angle = 90, vjust = 0.5))
source('~/Dropbox/work/papers/papers2017/TBD (airbnb)/data/cities.R', echo=TRUE)
ggplot(df, aes(x=bnb_penetration, y=ratio_apartments, label=city)) +
geom_label(size=2, alpha=0.5, aes(fill=country)) +
theme(legend.position="none")
source('~/Dropbox/work/papers/papers2017/TBD (airbnb)/data/cities.R', echo=TRUE)
